{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This is a Jupyter Notebook. It is an interactive document that contains both rich text elements such as figures, links, equations, etc. and executable code - in this case Python code (the grey boxes).\n",
    "**How to use a Jupyter Notebook**: You can execute the blocks of code one at the time by placing the mouse in the grey box and pressing shift + enter. An asterisk will appear in the brackets at the top left of the box while the code is being executed (this may take few seconds) and turns into a number when the execution is over. Alternatively, you can run all the code in the Notebook in a single step by clicking on the menu Cell -> Run All.*\n",
    "\n",
    "## GSA tutorial - Epidemiological modelling example\n",
    "Francesca Pianosi, Fanny Sarrazin, Andres Penuela-Fernandez\n",
    "\n",
    "Mathematical models are often used to inform decision-makers dealing with complex management problems. The model is used to predict the consequences of alternative actions, hence providing a quantitative assessment of their benefits and costs, possibly under different uncertain scenarios. In this context, Global Sensitivity Analysis (GSA) can be used to explore the system response to decision-related parameters and other uncertain parameters in a structured way.\n",
    "\n",
    "In this Notebook we will use a simple epidemiological model, which provides a mathematical description of the spread of an infectious deasease, such as flu, within a population. \n",
    "\n",
    "The **model** divides the population into three \"compartments\":\n",
    "* Vulnerable: individuals who are vulnerable but not yet infected with the flu\n",
    "* Sick: individuals who are infected with the flu\n",
    "* Immune: individuals who have immunity to the flu. This includes individuals who either have recovered from the flu or have been vaccinated.\n",
    "\n",
    "The model describes the change in the number of individuals in each compartment over time, using five parameters:\n",
    "* <font color='blue'>Initial number of vaccinated individuals</font>: people who are immune at the start of the flu season because they were previously vaccinated.\n",
    "* <font color='blue'>Recovery time</font>: the average number of days to get fully recovered\n",
    "* <font color='green'>Contact rate per day</font>: number of times that an infected individual comes into contact with a vulnerable individual in a day\n",
    "* <font color='green'>Contagion ratio</font>: proportion of contacts that result in infection\n",
    "* <font color='green'>Vaccination rate</font>: number of inviduals who are vaccinated per day during the outbreak\n",
    "\n",
    "Let's consider the following **decision-making problem**. In a city with a population of 100,000 people, we would like to simulate and compare three possible actions to be taken during the flu season:\n",
    "* Implementing social distancing measures to reduce the <font color='green'>daily contact rate</font>. A reduction of 0.1 points of this rate is estimated to cost £20,000.\n",
    "* Distributing face masks to reduce the <font color='green'>contagion rate</font>. Reducing this rate by 0.1 points is estimated to cost £5,000.\n",
    "* Increasing the <font color='green'>vaccination rate</font> during the flu season. The vaccination cost is of £7 per person.\n",
    "\n",
    "The objective is to keep the sick population below 25% (25,000 people) at any time with a budget of £300,000. However, the effects of our decisions also depend on <font color='blue'>initial number of vaccinated individuals</font> at the start of the flu season, and the <font color='blue'>recovery time</font>. Both these factors are not known exactly, and it can only be estimated that the number of people initially vaccinated should range between 0 and 50,000 and the recovery time should vary between 7 and 14 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages\n",
    "Before starting, we need to import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import, print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to hide warning messages\n",
    "\n",
    "# Install python package for interactive visualisation and import required functions:\n",
    "#%pip install -q ipywidgets\n",
    "from ipywidgets import interact, FloatRangeSlider, IntRangeSlider\n",
    "\n",
    "# Install SAFE package and import required functions\n",
    "!pip install SAFEpython\n",
    "import safepython.RSA_thres as RSA_tr # Module that implements RSA\n",
    "import safepython.plot_functions as pf # Module to visualize the results\n",
    "from safepython.model_execution import model_execution # Module to execute the model\n",
    "from safepython.sampling import AAT_sampling, AAT_sampling_extend # Functions to perform the input sampling\n",
    "from safepython.util import aggregate_boot # Functions to perform bootstrapping\n",
    "from safepython.util import empiricalcdf\n",
    "# Module that simulates the epidemiological model:\n",
    "import flu_fun as flu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - One-At-the-Time 'what-if?' analysis\n",
    "In this section, we will run the epidemiological model by changing its parameters one at the time. Execute the block of code below, and then use the slider to change the parameter values. \n",
    "* Can you determine a combination of decion-related parameters (*contagion ratio*, *recovery time*, *vaccination rate*) that maintain number of sick individuals at peak below **25,000** at all times, for a total cost of less than **£300,000** - under as as many combinations as possible of *initial vaccinated population* and *recovery time*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nday = 100 # days\n",
    "Npop = 100000 # individuals in the total population\n",
    "target1 =  25000 # target for max number of sick individuals\n",
    "target2 = 350000 # target for max cost (£)\n",
    "t = np.linspace(1,Nday,Nday)\n",
    "def oat_function(contag_ratio = 2, recovery_day = 14, vax_rate=2500,pop_vax_ini = 0, contact_rate = 2):\n",
    "    # Set a tentative parameterization:\n",
    "    param = np.array([pop_vax_ini, contact_rate, contag_ratio, recovery_day, vax_rate])    \n",
    "    # Run simulation:\n",
    "    \n",
    "    S, RI, V,max_value,total_cost = flu.model(param,t,Npop)\n",
    " \n",
    "    # Plot results:\n",
    "    plt.figure(figsize=[12,3])\n",
    "    plt.stackplot(t,S,V,RI,labels=['Sick','Vulnerable','Immune'])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.plot(target1*np.ones((Nday,1)),'r' )\n",
    "    plt.ylabel('population')\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.title(\"No. of sick individuals at peak = %d\" % (max_value) + \" (target: %d\" % (target1) + \")      Total cost (£) = %d\" % (total_cost) + \" (target: %d\" % (target2) + \")\")\n",
    "    plt.xlim((1,Nday))\n",
    "    plt.show()\n",
    "    \n",
    "interact(oat_function, contag_ratio = (0.3, 1, 0.01), recovery_day = (7, 14, 1), vax_rate = (0,5000,10), pop_vax_ini = (0,50000,10), contact_rate = (0.3, 2, 0.01));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Global Sensitivity Analysis\n",
    "We can see that it is difficult to find a combination of actions that robustly achieve both targets by varying the parameter values one at the time. In order to facilitate this search, we can use Global Sensitivity Analysis (GSA) to answer questions like:\n",
    "- is it possible at all to find a set of actions (i.e. decision-related parameters) that satisfy both targets against many uncertain scenarios?\n",
    "- which of these decision-related parameters are key to achieve the desired outputs? \n",
    "- which uncertainties are most influential and should be prioritised for uncertainty reduction?\n",
    "- if we could reduce these important uncertainties, what would emerge as best combination of actions to undertake?\n",
    "\n",
    "In GSA, we first generate a number of parameter combinations by randomly sampling from the feasible parameter ranges. Then, we run the model against each of these combinations (this is called Monte Carlo simulations). The results of each model run is associated with our two output metrics of interest: the number of sick individuals at the outbreak peak, and the total vaccination cost. Then, we analyse this sample of parameter combinations and associated output metrics through a mix of qualitative (visual analysis) and quantitative (sensitivity indices) approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Monte Carlo simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variability space:\n",
    "X_Labels = ['pop_vax_ini', 'contact_rate', 'contag_ratio', 'recovery_day', 'vax_rate'] # Name of parameters (used to customize plots)\n",
    "M = len(X_Labels) # Number of parameters\n",
    "distr_fun = st.uniform # Parameter distributions\n",
    "xmin = [ 0   , 0.3, 0.3,  7,    0] # Parameter ranges (lower bound)\n",
    "xmax = [50000, 2.0, 1.0, 14, 5000] # Parameter ranges (upper bound)\n",
    "# Save lower and upper bound in the appropriate format to be passed on to the sampling function:\n",
    "distr_par = [np.nan] * M\n",
    "for i in range(M):\n",
    "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
    "samp_strat = 'lhs' # sampling strategy (options: 'lhs' = Latin Hypercube sampling,'rsu' = Random uniform sampling)\n",
    "N = 2000 # Number of samples\n",
    "X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N) # Perform sampling\n",
    "# Execute the model against all the samples in 'X':\n",
    "Y1 = model_execution(flu.function, X,t,Npop,0) # max number of sick individuals in a day\n",
    "Y2 = model_execution(flu.function, X,t,Npop,1) # total cost of the measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing Monte Carlo samples to quantify output uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency distribution of outputs:\n",
    "Y_Labels = ['sicks at peak','total cost']\n",
    "\n",
    "plt.figure(figsize=[13,4])\n",
    "plt.subplot(1,3,1), plt.title('Distribution of output samples', loc='left'), plt.hist(Y1, bins=20, color='grey');\n",
    "plt.axvline(x=target1, color='r'), plt.ylim((0,N)), plt.ylabel('number of samples'), plt.xlabel(Y_Labels[0])\n",
    "\n",
    "plt.subplot(1,3,2), plt.hist(Y2, bins=20, color='grey'), plt.axvline(x=target2, color='r')\n",
    "plt.ylim((0,N)), plt.xlabel(Y_Labels[1]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1,3,3), plt.title('Output 1 vs 2', loc='left')\n",
    "plt.plot(Y1,Y2/10000, '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "plt.xlabel(Y_Labels[0]), plt.ylabel(Y_Labels[1]+ \"(x £10,000) \"), plt.axvline(x=target1, color='r')\n",
    "plt.axhline(y=target2/10000, color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions** \n",
    "* How frequently does the number of sick individuals at outbreak peak remain below target? In other words, what are the chances of achieving the target for this output?\n",
    "* And what are the chances of achieving the target for total cost? \n",
    "* Is there a tradeoff between the two targets?\n",
    "* Is it possible to reach both targets simoultaneously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Sensitivity indices\n",
    "Now, we use the input-output samples generated in the previous step to calculate sensitivity indices. We usa a GSA method called *Regional Sensitivity Analysis*, or *Monte Carlo filtering* (more insights about how the methods works to calculate sensitivity indices are given in the last section of this Notebook). We calculate three sets of indices, each measuring the relative importance of the 5 input parameters towards:\n",
    "- achieving the target for the number of sick individuals at peak (output 1)\n",
    "- achieving the target for the total costs (output 2)\n",
    "- achieving both targets simoultaneously (output 1&2 jointly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nboot = 50 # Number of resamples used for bootstrapping\n",
    "Y_Labels = ['output1=sicks at peak','output2=total cost','output1&2 jointly']\n",
    "for i in range(3):\n",
    "    if i==0:\n",
    "        Y=Y1\n",
    "        target=target1\n",
    "    if i==1:\n",
    "        Y=Y2\n",
    "        target=target2\n",
    "    if i==2:\n",
    "        Y = np.concatenate((Y1,Y2),axis=1)\n",
    "        target = [target1,target2]\n",
    "    # plot:\n",
    "    plt.figure(figsize=[7,2])\n",
    "    mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y, target, Nboot=Nboot)\n",
    "    mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "    yerr=np.c_[mvd_m-mvd_lb,mvd_ub-mvd_m].T\n",
    "    plt.bar(range(len(mvd_m)), mvd_m, color='grey',yerr=yerr)\n",
    "    plt.title(Y_Labels[i], loc='center'), plt.xticks(range(len(mvd_m)), X_Labels), plt.ylabel('Sensitivity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* what are the most important factors to keep the number of sick individuals at peak below target? \n",
    "* are the same factors equally important to control the total cost?\n",
    "* which of the decision-related parameters are key to achieve the desired outputs?\n",
    "* which of the inputs uncertainties is most influential and should be prioritised for uncertainty reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing input samples to identify 'robust' decisions\n",
    "\n",
    "Last, we can look for the most robust combinations of actions (<font color='green'>vaccination rate</font>, <font color='green'>contact rate</font>, and <font color='green'>contagion ratio</font>) - i.e. combinations that will result in reaching the set targets across the largest possible range of uncertainties. We can also analyse how these robust actions change with changing level of uncertainty - for instance as we reduce the uncertainty range around the <font color='blue'>initial number of vaccinated individuals</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vax_ini_function(vax_ini_min = 0, vax_ini_max = 40000):\n",
    "\n",
    "    vax_ini_idx = ( X[:,0]> vax_ini_min ) & ( X[:,0]< vax_ini_max )\n",
    "    Xr = np.zeros((sum(vax_ini_idx),M))\n",
    "    for i in range(5):\n",
    "        Xr[:,i]=X[vax_ini_idx,i]\n",
    "    Y1r = Y1[vax_ini_idx]\n",
    "    Y2r = Y2[vax_ini_idx]\n",
    "  \n",
    "    Yr = np.concatenate((Y1r,Y2r),axis=1)\n",
    "    target = [target1,target2]\n",
    "    mvd, _, _, idx = RSA_tr.RSA_indices_thres(Xr, Yr, target)\n",
    "\n",
    "    plt.figure(figsize=[15,4])\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(Xr[:, 4], Xr[:, 1]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,4], Xr[idx, 1], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[4]), plt.ylabel(X_Labels[1])\n",
    "    plt.title(\"Combinations of actions (red) that will keep both outputs below target for given range of vax_ini\", loc='left')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(Xr[:, 4], Xr[:, 2]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,4], Xr[idx, 2], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[4])\n",
    "    plt.ylabel(X_Labels[2])\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(Xr[:, 1], Xr[:, 2]   , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "    plt.plot(Xr[idx,1], Xr[idx, 2], '.', markerfacecolor='r', markeredgecolor='r')\n",
    "    plt.xlabel(X_Labels[1])\n",
    "    plt.ylabel(X_Labels[2])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interact(vax_ini_function, vax_ini_min = (0,40000,1000), vax_ini_max = (0,40000,1000));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is there any clear interaction between the parameters? (for example, one need to be reduced if the other is increased in order to ensure reaching the targets?). \n",
    "* Do these interactions become clearer if we reduce the uncertainty in the initial number of vaccinated individuals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced steps: investigating how Regional Sensitivity Analysis works\n",
    "This last section is for those who want to dig deeper in how sensitivity indices are derived when using Regional Sensitivity Analysis (for more background on this method, see Spear and Hornberger 1980 or Pianosi et al. 2016) and the impact of varying the target threshold on sensitivity results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsa_function(peak_target = target1, cost_target = target2):\n",
    "    # Use the function RSA_indices_thres to split into behavioural (Y<threshold)\n",
    "    # and non-behavioural (Y>threshold) sample:\n",
    "    Y = np.concatenate((Y1,Y2),axis=1)\n",
    "    threshold = [peak_target,cost_target]\n",
    "    Nboot = 50 # Number of resamples used for bootstrapping\n",
    "    mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, Y, threshold, Nboot=Nboot)\n",
    "    mvd_m, mvd_lb, mvd_ub = aggregate_boot(mvd) # shape (M,)\n",
    "\n",
    "    plt.figure(figsize=[15,8])\n",
    "    # Scatter plots of Output 1 versus each input parameter\n",
    "    for i in range(M):\n",
    "        plt.subplot(3,M,i+1)\n",
    "        plt.plot(X[:, i], Y1/1000  , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "        plt.plot(X[idx,i], Y1[idx, :]/1000, '.', markerfacecolor='r', markeredgecolor='r')\n",
    "        if i==0:\n",
    "            plt.ylabel(Y_Labels[0] + \" (x1000)\")\n",
    "    # Scatter plots of Output 2 versus each input parameter\n",
    "    for i in range(M):\n",
    "        plt.subplot(3,M,M+i+1)\n",
    "        plt.plot(X[:, i], Y2/1000  , '.', markerfacecolor='0.8', markeredgecolor='0.8')\n",
    "        plt.plot(X[idx,i], Y2[idx, :]/1000, '.', markerfacecolor='r', markeredgecolor='r')\n",
    "        if i==0:\n",
    "            plt.ylabel(Y_Labels[1] + \" (£x1000)\")\n",
    "    # Empirical distribution of each parameter in the behavioural and non-behavioural set        \n",
    "    for i in range(M):\n",
    "        # Approximate behavioural and non-behavioural distributions:\n",
    "        Xb = X[idx, :]\n",
    "        Xnb = X[~idx, :]\n",
    "        xx = np.unique(sorted(X[:, i]))\n",
    "        CDFb  = empiricalcdf(Xb[:, i], xx)\n",
    "        CDFnb = empiricalcdf(Xnb[:, i], xx)\n",
    "        # Plot CDFs:\n",
    "        plt.subplot(3,M,M+M+i+1)\n",
    "        plt.plot(xx, CDFb , color='r')\n",
    "        plt.plot(xx, CDFnb, color='0.8')\n",
    "        plt.xlabel(X_Labels[i])\n",
    "        if i==0:\n",
    "            plt.ylabel(\"distribution\")\n",
    "            plt.legend(['on target','off target'])\n",
    "    plt.show()\n",
    "\n",
    "    # The sensitivity indices with their 95% confidence intervals:\n",
    "    plt.figure(figsize=[7,2])\n",
    "    yerr=np.c_[mvd_m-mvd_lb,mvd_ub-mvd_m].T\n",
    "    plt.bar(range(len(mvd_m)), mvd_m, color='grey',yerr=yerr)\n",
    "    plt.xticks(range(len(mvd_m)), X_Labels)\n",
    "    plt.ylabel('Sensitivity')\n",
    "\n",
    "    plt.show()\n",
    "interact(rsa_function, peak_target = (target1-20000,target1+20000,100), cost_target = (250000, 400000, 100));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Pianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis’. Env. Mod. & Soft., 70, 80-85.\n",
    "\n",
    "Pianosi et al. (2016). Sensitivity analysis of environmental models: A systematic review with practical workflow, Env. Mod. & Soft.e, 79, 214-232.\n",
    "\n",
    "Spear and Hornberger (1980). Eutrophication in peel inlet. II. Identification of critical uncertainties via generalized sensitivity analysis, Water Res., 14, 43-49.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
