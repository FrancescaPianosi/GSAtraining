{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "*This is a Jupyter Notebook. It is an interactive document that contains both rich text elements such as figures, links, equations, etc. and executable code - in this case Python code (the grey boxes).\n**How to use a Jupyter Notebook**: You can execute the blocks of code one at the time by placing the mouse in the grey box and pressing shift + enter. An asterisk will appear in the brackets at the top left of the box while the code is being executed (this may take few seconds) and turns into a number when the execution is over.*\n\n*This notebook and underpinning code were developed by Francesca Pianosi (francesca.pianosi@bristol.ac.uk) and are distributed under the GPL 3.0 licence: https://www.gnu.org/licenses/gpl-3.0.html*\n\n\n# GSA tutorial - Hydrological modelling example\nFrancesca Pianosi, Fanny Sarrazin, Andres Pe√±uela\n\nIn this Notebook we show how Global Sensitivity Analysis (GSA) can be used us to investigate the relative importance of model parameters on a range of model outputs, and therefore identify the most influential parameters on which estimation efforts should be focused on.\n\nWe will apply GSA to a **lumped hydrological model**, which takes time series of meteorological forcings (rainfall and temperature) over a catchment, and returns the time series of river flows at the catchment outlet. Here we will use the GR6J model (Pushpalatha et al 2011), which has six parameters:\n- X1: production store capacity [mm]\n- X2: intercatchment exchange coefficient [mm/d]\n- X3: routing store capacity [mm]\n- X4: unit hydrograph time constant [d]\n- X5: intercatchment exchange threshold [-]\n- X6: exponential store depletion coefficient [mm]\n\nTo measure the model ability to reproduce the flow observations, we will use three **performance metrics** (all to be minimised):\n- Correlation: $ \\ \\ \\ C = ( r - 1 )^2 \\ \\ $ where $ \\ \\ \\ r $ is the correlation between the observed flow time series ($Q^{obs}$) and the simulated flow time series ($Q^{sim}$)\n- Variability: $ \\ \\ \\ V = ( S_{sim} / S_{obs} - 1 )^2 \\ \\ $ where $S_{sim}$ ($S^{obs}$) is the standard deviation of the time series $Q^{sim}$ ($Q^{obs}$).\n- Bias: $ \\ \\ \\ B =  ( M_{sim} / M_{obs} - 1 )^2 \\ \\ $ where $M^{sim}$ ($M^{obs}$) is the mean of $Q^{sim}$ ($Q^{obs}$)\n\nWe will also use a fourth metric, which is widely used in hydrology under the name of King-Gupta Efficiency (https://en.wikipedia.org/wiki/Kling%E2%80%93Gupta_efficiency), and is a combination of C, V and B:\n\n- King-Gupta Efficiency: $ \\ \\ \\ KGE = 1 - \\sqrt{ C + V + B } $ \n\nBy definition, KGE varies between $- \\infty $ and 1, where 1 is the value that would be achieved by a perfect model with no error in correlation, variability and bias. Differently from C, V and B thus, the KGE is to be maximised.\n\nWe will use time series of precipitation, potential evaporation, and river flows of an example catchment, the Wick River at Tarroul: https://nrfa.ceh.ac.uk/data/station/spatial/1001.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Import libraries\nBefore starting, we need to import some packages",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from __future__ import division, absolute_import, print_function\n\n# General Python Packages needed for calculation\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\n\n# Specific functions needed for model simulation and calibration\nfrom GR6J import gr6j_sim as gr6j_sim\nfrom PerfMetrics import CORR_ERR as CORR_ERR\nfrom PerfMetrics import MEAN_ERR as MEAN_ERR\nfrom PerfMetrics import STD_ERR as STD_ERR\n\n# Install python package for interactive visualisation and import required functions:\n%pip install -q ipywidgets\nfrom ipywidgets import interact, FloatRangeSlider, IntRangeSlider\nimport warnings\nwarnings.filterwarnings('ignore') # to hide warning messages\nfrom IPython.display import display, HTML\n# Increase size of output display cell:\ndisplay(HTML(\"\"\"\n<style>\n    div.output_scroll {height: 40em; }\n</style>\n\"\"\"))\n\n# Install SAFE package and import required functions\n%pip install SAFEpython\nimport safepython.PAWN as PAWN # Module to calculate PAWN sensitivity indices\nimport safepython.plot_functions as pf # Module to visualize the results\nfrom safepython.model_execution import model_execution # Module to execute the model\nfrom safepython.sampling import AAT_sampling, AAT_sampling_extend # Functions to perform the input sampling\nfrom safepython.util import aggregate_boot # Functions to perform bootstrapping\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Load rainfall, evap and flow data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Load the data:\ndata = pd.read_csv(\"CAMELS_GB_1001.csv\")\nrain = data[\"precipitation\"].to_numpy() # (mm/day)\nevap = data[\"pet\"].to_numpy() # (mm/day)\nflow = data[\"discharge_spec\"].to_numpy() # (mm/day)\n\n# Select a sub-period of the available time series for plotting and further analysis:\nrain_sel = rain[280:280+364*3] # \nevap_sel = evap[280:280+364*3]\nflow_sel = flow[280:280+364*3]\n\n# Plot:\nplt.figure(figsize=[15,7])\nplt.subplot(311); plt.plot(rain_sel,'g'); plt.ylabel('rainfall (mm/day)')\nplt.subplot(312); plt.plot(evap_sel,'g'); plt.ylabel('evaporation (mm/day)')\nplt.subplot(313); plt.plot(flow_sel,'g'); plt.ylabel('flow (mm/day)')\nplt.xlabel('time (days)')\n           \nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## 1 - One-At-the-Time Sensitivity Analysis\nWe are now ready to run the GR6J model. To do this, we will set the six model parameters to some tentative values, run the model and plot the resulting streamflow time series. We can then change the parameter values one-at-a-time and look at how this changes the model predictions, and their fit to observed flows.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define interactive visualisation function to set the parameters to some tentative values, \n# run the model and plot the resulting streamflow time series\n\ndef oat_function(x1 = 200, x2 = 0.3, x3 = 100, x4 = 3, x5 = 0.6, x6 = 80 ):\n    \n    # Run simulation:\n    x = np.array([x1, x2, x3, x4, x5, x6]) \n    flow_sim, _, _ = gr6j_sim(x, rain_sel, evap_sel, np.zeros((3, )))\n    C = CORR_ERR(flow_sim, flow_sel)\n    B = MEAN_ERR(flow_sim, flow_sel)\n    V = STD_ERR(flow_sim, flow_sel)\n    KGE = 1-(C+B+V)**0.5 \n    # Plot hydrograph of observed and simulated flow:    \n    fig = plt.figure(figsize=[12,3])    \n    plt.plot(flow_sel, 'g') # observed flow\n    plt.plot(flow_sim, 'k') # simulated flow\n    plt.ylabel('flow (mm/day)')\n    plt.xlabel('time (days)')\n    plt.legend(['obs', 'sim']) \n    plt.title(\"Correlation: C = %0.3f\" % C + \", Variability: V = %0.3f\" % V + \", Bias: B = %0.3f\" % B + \", KGE = %0.3f\" % KGE, loc='center')\n    plt.show()\n   \ninteract(oat_function, x1 = (0, 400, 1), x2 = (0, 3, 0.1), x3 = (10,150,1), x4 = (0,10,1), x5 = (0.1,1,0.1), x6 = (0.1,100,1));",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "##  2 - Global Sensitivity Analysis\nIn this section, we run Monte Carlo (MC) simulations of the model against a prescribed number of parameter combinations, randomly drawn from the feasible parameter ranges. Each model simulation provides a times series of streamflow predictions. For each time series, we will measure the distance from observations through different performance metrics. We can then analyse the sensitivity of these metrics to the different parameters.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "###  Run Monte Carlo simulations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define variability ranges of the parameters:\nxmin = [0  , 0,   10,  0, 0.1, 0.1] # min values\nxmax = [300, 0.5,  50, 10, 0.5, 50  ] # max values\nN = 200 # Number of samples\nX_Labels = ['x1', 'x2', 'x3', 'x4', 'x5','x6'] # Name of parameters (used to customize plots)\nM = len(X_Labels) # Number of parameters\nsamp_strat = 'lhs' # sampling strategy\ndistr_fun = st.uniform # Parameter distributions\n# Save lower and upper bound in the appropriate format to be passed on to the sampling function:\ndistr_par = [np.nan] * M\nfor i in range(M):\n    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\nX = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n# Execute the model against all the input samples in 'X':\nQQ = model_execution(gr6j_sim, X, rain_sel, evap_sel, np.zeros((3, )))\n# Plot Monte Carlo (MC) simulations results and compare with data:\nplt.figure(figsize=[15,3])\nplt.plot(flow_sel, color='g') # plot for legend\nplt.plot(np.transpose(QQ), 'grey', linewidth = 0.1)\nplt.plot(flow_sel, color='g')\nplt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\nplt.legend(['obs', 'sim'])\nplt.title(\"Number of parameter samples: N = %d\" % N, loc='right')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "###  Aggregate time series into scalar output metric(s) and produce scatter plots:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "YY = np.nan * np.ones((N, 4))\nYY[:, 0] = CORR_ERR(QQ, flow_sel)\nYY[:, 1] = MEAN_ERR(QQ, flow_sel)\nYY[:, 2] = STD_ERR(QQ, flow_sel)\nYY[:, 3] = 1 - ( YY[:, 0]+YY[:, 1]+YY[:, 2] )**0.5\nY_Labels = ['CORRELATION','BIAS','VARIABILITY','KGE']\nplt.figure(figsize=[18,9])\nk=0\nfor j in range(P):    \n    for i in range(M):\n        plt.subplot(P,M,k+1)\n        plt.plot(X[:, i], YY[:,j], '.', markerfacecolor=\"white\", markeredgecolor=\"grey\")        \n        if i == 0:\n            plt.ylabel(Y_Labels[j])\n        else:\n            plt.yticks([])\n        if j == P-1:\n            plt.xlabel(X_Labels[i])\n        k=k+1        \nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Questions:\n* From these scatter plots, which parameter would you say is most influential? Why?\n* How does the answer changes with the chosen performance metric?\n* *Advanced hydrology question: Can you interpret why certain parameters are more important for a certain metric than others?*",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Calculate sensitivity indices\nIn this section, we formally assess the sensitivity of the performance metrics to the model parameters through the PAWN method (Pianosi and Wagener, 2018). The analysis can be repeated for each performance metric. For each metric, we can also assess the impact of the choice of the tuning parameters of the PAWN method: the number of conditioning interval (n), the aggregation statistic (median, mean, max) and the number of bootstrap resamples (Nboot) used to estimate confidence intervals of the PAWN indices.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "P=4\nY_Labels = ['CORRELATION','BIAS','VARIABILITY','KGE']\n\ndef pawn_function_allmetrics(n = 5, aggr = 'median',Nboot = 50):\n        # Apply PAWN - Tuning parameters:\n        # n = number of conditioning intervals\n        # aggr = statistic to aggregate KS values\n        # Nboot = number of bootstrapping resamples used to derive confidence bounds of sensitivity indices   \n    plt.figure(figsize=[18,3])\n    for j in range(P):       \n        # Extract output metric:\n        Y = YY[:, j];   \n        # Compute sensitivity indices for Nboot bootstrap resamples\n        KS_median, KS_mean, KS_max = PAWN.pawn_indices(X, Y, n, Nboot=Nboot) # shape (Nboot, M)        \n        # Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:\n        KS_median_m, KS_median_lb, KS_median_ub = aggregate_boot(KS_median) # shape (M,)\n        KS_mean_m, KS_mean_lb, KS_mean_ub = aggregate_boot(KS_mean) # shape (M,)\n        KS_max_m, KS_max_lb, KS_max_ub = aggregate_boot(KS_max) # shape (M,)\n        # Plot sensitivity indices:\n        plt.subplot(1,4,j+1)\n        fs = 10 \n        plt.title(\"Output metric = %s\" % Y_Labels[j],fontsize=fs)\n        if aggr == 'median':\n            pf.boxplot1(KS_median_m, S_lb=KS_median_lb, S_ub=KS_median_ub, X_Labels=X_Labels)\n        if aggr == 'mean':\n            pf.boxplot1(KS_mean_m, S_lb=KS_mean_lb, S_ub=KS_mean_ub, X_Labels=X_Labels)\n        if aggr == 'max':\n            pf.boxplot1(KS_max_m, S_lb=KS_max_lb, S_ub=KS_max_ub, X_Labels=X_Labels)\n        if j > 0:\n            plt.ylabel(''); \n        else:\n            plt.ylabel('sensitivity',fontsize=fs)     \n        plt.xticks(fontsize=fs)\n        plt.yticks(fontsize=fs)        \n    plt.show()\n    \ninteract(pawn_function_allmetrics, n = (3, 15, 1), aggr = ['median', 'mean','max'], Nboot = (0, 100, 10));\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Questions:\n* Which parameter are most influential on each performance metric?\n* Are these results consistent with the visual inspection of the scatter plots?\n* *Advanced GSA question: What is the impact of changing n and Nboot? Why?*",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### References\n\nPianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis‚Äô. Env. Mod. & Soft., 70, 80-85.\n\nPianosi and Wagener (2018). Distribution-based sensitivity analysis from a generic input-output sample, Env. Mod. & Soft., 108, 197-207.\n\nPushpalatha, R., Perrin, C., Le Moine, N., Mathevet, T. and Andr√©assian, V. (2011). A downward structural sensitivity analysis of hydrological models to improve low-flow simulation. Journal of Hydrology, 411(1-2), 66-76, doi:10.1016/j.jhydrol.2011.09.034.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}