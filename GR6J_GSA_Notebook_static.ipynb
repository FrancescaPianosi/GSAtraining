{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*This is a Jupyter Notebook. It is an interactive document that contains both rich text elements such as figures, links, equations, etc. and executable code - in this case Python code (the grey boxes).\n",
        "**How to use a Jupyter Notebook**: You can execute the blocks of code one at the time by placing the mouse in the grey box and pressing shift + enter. An asterisk will appear in the brackets at the top left of the box while the code is being executed (this may take few seconds) and turns into a number when the execution is over.*\n",
        "\n",
        "*This notebook and underpinning code were developed by Francesca Pianosi (francesca.pianosi@bristol.ac.uk) and are distributed under the GPL 3.0 licence: https://www.gnu.org/licenses/gpl-3.0.html*\n",
        "\n",
        "\n",
        "# GSA tutorial - Hydrological modelling example\n",
        "Francesca Pianosi\n",
        "\n",
        "In this Notebook we show how Global Sensitivity Analysis (GSA) can be used us to investigate the relative importance of model parameters on a range of model outputs, and therefore identify the most influential parameters on which estimation efforts should be focused on.\n",
        "\n",
        "## The rainfall-runoff GR6J model\n",
        "We will apply GSA to a **lumped hydrological model**, which takes time series of meteorological forcings (rainfall and temperature) over a catchment, and returns the time series of river flows at the catchment outlet. Here we will use the GR6J model (Pushpalatha et al 2011), which has six parameters:\n",
        "- X1: production store capacity [mm]\n",
        "- X2: intercatchment exchange coefficient [mm/d]\n",
        "- X3: routing store capacity [mm]\n",
        "- X4: unit hydrograph time constant [d]\n",
        "- X5: intercatchment exchange threshold [-]\n",
        "- X6: exponential store depletion coefficient [mm]\n",
        "\n",
        "## The performance metrics\n",
        "To measure the model ability to reproduce the flow observations, we will use three **performance metrics** (all to be minimised):\n",
        "- Correlation: $ \\ \\ \\ C = ( r - 1 )^2 \\ \\ $ where $ \\ \\ \\ r $ is the correlation between the observed flow time series ($Q^{obs}$) and the simulated flow time series ($Q^{sim}$)\n",
        "- Variability: $ \\ \\ \\ V = ( S_{sim} / S_{obs} - 1 )^2 \\ \\ $ where $S_{sim}$ ($S^{obs}$) is the standard deviation of the time series $Q^{sim}$ ($Q^{obs}$).\n",
        "- Bias: $ \\ \\ \\ B =  ( M_{sim} / M_{obs} - 1 )^2 \\ \\ $ where $M^{sim}$ ($M^{obs}$) is the mean of $Q^{sim}$ ($Q^{obs}$)\n",
        "\n",
        "We will also use a fourth metric, which is widely used in hydrology under the name of King-Gupta Efficiency (https://en.wikipedia.org/wiki/Kling%E2%80%93Gupta_efficiency), and is a combination of C, V and B:\n",
        "\n",
        "- King-Gupta Efficiency: $ \\ \\ \\ KGE = 1 - \\sqrt{ C + V + B } $\n",
        "\n",
        "By definition, KGE varies between $- \\infty $ and 1, where 1 is the value that would be achieved by a perfect model with no error in correlation, variability and bias. Differently from C, V and B thus, the KGE is to be maximised.\n",
        "\n",
        "We will use time series of precipitation, potential evaporation, and river flows from the CAMELS-GB (Coxon et al. 2020) of an example catchment: https://nrfa.ceh.ac.uk/data/station/spatial/54025.\n"
      ],
      "metadata": {
        "id": "B0oqEXF-mI_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n",
        "Before starting, we need to import some packages"
      ],
      "metadata": {
        "id": "iLYXmgT_mI_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division, absolute_import, print_function\n",
        "\n",
        "# General Python Packages needed for calculation\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "\n",
        "# Specific functions needed for model simulation and calibration\n",
        "from GR6J import gr6j_sim as gr6j_sim\n",
        "from PerfMetrics import CORR_ERR as CORR_ERR\n",
        "from PerfMetrics import MEAN_ERR as MEAN_ERR\n",
        "from PerfMetrics import STD_ERR as STD_ERR\n",
        "\n",
        "# Install SAFE package and import required functions\n",
        "%pip install SAFEpython\n",
        "import safepython.PAWN as PAWN # Module to calculate PAWN sensitivity indices\n",
        "import safepython.plot_functions as pf # Module to visualize the results\n",
        "import safepython.RSA_thres as RSA_tr # Module that implements RSA\n",
        "from safepython.model_execution import model_execution # Module to execute the model\n",
        "from safepython.sampling import AAT_sampling, AAT_sampling_extend # Functions to perform the input sampling\n",
        "from safepython.util import aggregate_boot # Functions to perform bootstrapping\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "AglQ8wnrmI_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c8addd-a09f-4522-f18e-ab6e69756a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SAFEpython\n",
            "  Downloading safepython-0.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from SAFEpython) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.12/dist-packages (from SAFEpython) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from SAFEpython) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2.3->SAFEpython) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.3->SAFEpython) (1.17.0)\n",
            "Downloading safepython-0.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SAFEpython\n",
            "Successfully installed SAFEpython-0.2.0\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load rainfall, evap and flow data"
      ],
      "metadata": {
        "id": "jjU2Q4fMmI_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data:\n",
        "data = pd.read_csv(\"CAMELS_GB_hydromet_timeseries_54025_19701001-20150930.csv\")\n",
        "rain = data[\"precipitation\"].to_numpy() # (mm/day)\n",
        "evap = data[\"pet\"].to_numpy() # (mm/day)\n",
        "flow = data[\"discharge_spec\"].to_numpy() # (mm/day)\n",
        "\n",
        "# Select a sub-period of the available time series for further analysis:\n",
        "rain_sel = rain[280:280+364*3] #\n",
        "evap_sel = evap[280:280+364*3]\n",
        "flow_sel = flow[280:280+364*3]\n",
        "\n",
        "# Plot:\n",
        "plt.figure(figsize=[15,7])\n",
        "plt.subplot(311); plt.plot(rain_sel,'g'); plt.ylabel('rainfall (mm/day)')\n",
        "plt.subplot(312); plt.plot(evap_sel,'g'); plt.ylabel('evaporation (mm/day)')\n",
        "plt.subplot(313); plt.plot(flow_sel,'g'); plt.ylabel('flow (mm/day)')\n",
        "plt.xlabel('time (days)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0C6a9xZfmI_T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - One-At-the-Time Sensitivity Analysis\n",
        "We are now ready to run the GR6J model. To do this, we will set the six model parameters to some tentative values, run the model and plot the resulting streamflow time series. We can then change the parameter values one-at-a-time and look at how this changes the model predictions, and their fit to observed flows."
      ],
      "metadata": {
        "id": "u-ThJoykmI_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following cell to define the parameter values:"
      ],
      "metadata": {
        "id": "3T4PBXFqHpNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = 200 # must vary between 0 and 400\n",
        "x2 = 0.3 # must vary between 0 and 3\n",
        "x3 = 100 # must vary between 10 and 150\n",
        "x4 = 3 # must vary between 0 and 10\n",
        "x5 = 0.6 # must vary between 0.1 and 1\n",
        "x6 = 80 # must vary between 0.1 and 100"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y41K7TpFmI_T"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and execute the following cell to run the model and plot the simulation results"
      ],
      "metadata": {
        "id": "PFnvnBazIIkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run simulation:\n",
        "x = np.array([x1, x2, x3, x4, x5, x6])\n",
        "flow_sim, _, _ = gr6j_sim(x, rain_sel, evap_sel, np.zeros((3, )))\n",
        "C = CORR_ERR(flow_sim, flow_sel)\n",
        "B = MEAN_ERR(flow_sim, flow_sel)\n",
        "V = STD_ERR(flow_sim, flow_sel)\n",
        "KGE = 1-(C+B+V)**0.5\n",
        "# Plot hydrograph of observed and simulated flow:\n",
        "fig = plt.figure(figsize=[12,3])\n",
        "plt.plot(flow_sel, 'g') # observed flow\n",
        "plt.plot(flow_sim, 'k') # simulated flow\n",
        "plt.ylabel('flow (mm/day)')\n",
        "plt.xlabel('time (days)')\n",
        "plt.legend(['obs', 'sim'])\n",
        "plt.title(\"Correlation: C = %0.3f\" % C + \", Variability: V = %0.3f\" % V + \", Bias: B = %0.3f\" % B + \", KGE = %0.3f\" % KGE, loc='center')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-ikk6s4mHcuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "* What happens if you go back to the definition of the parameters and change one of them?\n",
        "* What parameter controls what aspect of the hydrograph (magnitude and timing of the flow peaks, spead of the recession curve, minimum flow value, etc.)?\n",
        "* How does the change in hydrograph reflect into change in performance metric?\n",
        "* Can you find a parameter combination that delivers a good fit to the observations?"
      ],
      "metadata": {
        "id": "bRMdQZprLi0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  2 - Global Sensitivity Analysis\n",
        "In this section, we run Monte Carlo simulations of the model against a prescribed number of parameter combinations, randomly drawn from the feasible parameter ranges. Each model simulation provides a times series of streamflow predictions. For each time series, we will measure the distance from observations through different performance metrics. We can then analyse the sensitivity of these metrics to the different parameters."
      ],
      "metadata": {
        "id": "_GXRzr3lmI_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Run Monte Carlo simulations\n",
        "\n",
        "In order to run Monte Carlo simulations, we need to make few choices: 1) the parameter ranges from which parameter combinations will be randomly sampled; 2) the number of parameter combinations to be sampled. This is done in the next cell (change the code if you want to make different choices!)"
      ],
      "metadata": {
        "id": "IGf2XE9fmI_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variability ranges of the parameters:\n",
        "xmin = [0  , 0,   10,  0, 0.1, 0.1  ] # min values\n",
        "xmax = [300, 0.5,  50, 10, 0.5, 50  ] # max values\n",
        "# Choose number of parameter combinations to be sampled:\n",
        "N = 200"
      ],
      "metadata": {
        "trusted": true,
        "id": "dpVpRqY7mI_U",
        "collapsed": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to run the Monte Carlo simulations (this may take few seconds if you have selected a large value of N) and plot the resulting simulated time series."
      ],
      "metadata": {
        "id": "L0mZ84YBmI_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = len(xmin) # Number of parameters\n",
        "samp_strat = 'lhs' # sampling strategy\n",
        "distr_fun = st.uniform # Parameter distributions\n",
        "# Save lower and upper bound in the appropriate format to be passed on to the sampling function:\n",
        "distr_par = [np.nan] * M\n",
        "for i in range(M):\n",
        "    distr_par[i] = [xmin[i], xmax[i] - xmin[i]]\n",
        "X = AAT_sampling(samp_strat, M, distr_fun, distr_par, N)\n",
        "# Execute the model against all the input samples in 'X':\n",
        "QQ = model_execution(gr6j_sim, X, rain_sel, evap_sel, np.zeros((3, )))\n",
        "# Plot Monte Carlo (MC) simulations results and compare with data:\n",
        "plt.figure(figsize=[15,3])\n",
        "plt.plot(flow_sel, color='g') # plot for legend\n",
        "plt.plot(np.transpose(QQ), 'grey', linewidth = 0.1)\n",
        "plt.plot(flow_sel, color='g')\n",
        "plt.ylabel('flow (mm/day)'); plt.xlabel('time (days)')\n",
        "plt.legend(['obs', 'sim'])\n",
        "plt.title(\"Number of parameter samples: N = %d\" % N, loc='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lo-wrLNzynRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "* Does the envelope of simulated time series (grey) include the time series of observed flows?\n",
        "* If not, can you make that happen by expanding the parameter ranges and/or increasing the number of samples (N)?\n",
        "* *Advanced hydrology question: What other sources of errors may cause the mismatch between observations and simulations?*"
      ],
      "metadata": {
        "id": "hY0X5Usn0Let"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Produce scatter plots\n",
        "\n",
        "We can now calculate the performance metrics for each of the simulated time series and the produce scatter plots showing how performance varies against paramter values."
      ],
      "metadata": {
        "id": "C1lUxfiBz5Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following cell to choose which performance metric to look at (you can comment all options using # and uncomment the one you chose):"
      ],
      "metadata": {
        "id": "Yom8JsB9Igxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = 'CORRELATION'\n",
        "#metric = 'BIAS'\n",
        "#metric = 'VARIABILITY'\n",
        "#metric = 'KGE'"
      ],
      "metadata": {
        "id": "rXduS5v9Im3H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and execute the following cell to produce the scatter plots"
      ],
      "metadata": {
        "id": "8d0It0-eI_Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YY = np.nan * np.ones((N, 4))\n",
        "YY[:, 0] = CORR_ERR(QQ, flow_sel)\n",
        "YY[:, 1] = MEAN_ERR(QQ, flow_sel)\n",
        "YY[:, 2] = STD_ERR(QQ, flow_sel)\n",
        "YY[:, 3] = 1 - ( YY[:, 0]+YY[:, 1]+YY[:, 2] )**0.5\n",
        "X_Labels = ['x1', 'x2', 'x3', 'x4', 'x5','x6'] # Name of parameters (used to customize plots)\n",
        "Y_Labels = ['CORRELATION','BIAS','VARIABILITY','KGE']\n",
        "if metric == 'CORRELATION':\n",
        "    j = 0\n",
        "elif metric == 'BIAS':\n",
        "    j = 1\n",
        "elif metric == 'VARIABILITY':\n",
        "    j = 2\n",
        "elif metric == 'KGE':\n",
        "    j = 3\n",
        "plt.figure(figsize=[18,3])\n",
        "for i in range(M):\n",
        "    plt.subplot(1,M,i+1)\n",
        "    plt.plot(X[:, i], YY[:,j], '.', markerfacecolor=\"white\", markeredgecolor=\"grey\")\n",
        "    if i == 0:\n",
        "        plt.ylabel(Y_Labels[j])\n",
        "    else:\n",
        "        plt.yticks([])\n",
        "    plt.xlabel(X_Labels[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "rpmBEt6jmI_U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "* From these scatter plots, which parameter would you say is most influential? Why?\n",
        "* How does the answer changes with the chosen performance metric?\n",
        "* *Advanced hydrology question: Can you interpret why certain parameters are more important for a certain metric than others?*"
      ],
      "metadata": {
        "id": "Nj87wtb8mI_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate sensitivity indices with PAWN\n",
        "In this section, we formally assess the sensitivity of the performance metrics to the model parameters through the PAWN method (Pianosi and Wagener, 2018). The analysis can be repeated for each performance metric. For each metric, we can also assess the impact of the choice of the tuning parameters of the PAWN method: the number of conditioning interval (n), the aggregation statistic (median, mean, max) and the number of bootstrap resamples (Nboot) used to estimate confidence intervals of the PAWN indices."
      ],
      "metadata": {
        "id": "-VY2Gtq8mI_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Labels = ['CORRELATION','BIAS','VARIABILITY','KGE']\n",
        "P=len(Y_Labels)\n",
        "\n",
        "\n",
        "# Choose the PAWN Tuning parameters:\n",
        "# n = number of conditioning intervals\n",
        "# aggr = statistic to aggregate KS values\n",
        "# Nboot = number of bootstrapping resamples used to derive confidence bounds of sensitivity indices\n",
        "n = 5 # vary between 3 and 15\n",
        "aggr = 'mean' # choose from 'mean','median' and 'max'\n",
        "Nboot = 50 # vary between 5 and 100\n",
        "\n",
        "plt.figure(figsize=[18,3])\n",
        "for j in range(P):\n",
        "    # Extract output metric:\n",
        "    Y = YY[:, j];\n",
        "    # Compute sensitivity indices for Nboot bootstrap resamples\n",
        "    KS_median, KS_mean, KS_max = PAWN.pawn_indices(X, Y, n, Nboot=Nboot) # shape (Nboot, M)\n",
        "    # Compute mean and confidence intervals of the sensitivity indices across the bootstrap resamples:\n",
        "    KS_median_m, KS_median_lb, KS_median_ub = aggregate_boot(KS_median) # shape (M,)\n",
        "    KS_mean_m, KS_mean_lb, KS_mean_ub = aggregate_boot(KS_mean) # shape (M,)\n",
        "    KS_max_m, KS_max_lb, KS_max_ub = aggregate_boot(KS_max) # shape (M,)\n",
        "    # Plot sensitivity indices:\n",
        "    plt.subplot(1,4,j+1)\n",
        "    fs = 10\n",
        "    plt.title(\"Output metric = %s\" % Y_Labels[j],fontsize=fs)\n",
        "    if aggr == 'median':\n",
        "        pf.boxplot1(KS_median_m, S_lb=KS_median_lb, S_ub=KS_median_ub, X_Labels=X_Labels)\n",
        "    if aggr == 'mean':\n",
        "        pf.boxplot1(KS_mean_m, S_lb=KS_mean_lb, S_ub=KS_mean_ub, X_Labels=X_Labels)\n",
        "    if aggr == 'max':\n",
        "        pf.boxplot1(KS_max_m, S_lb=KS_max_lb, S_ub=KS_max_ub, X_Labels=X_Labels)\n",
        "    if j > 0:\n",
        "        plt.ylabel('');\n",
        "    else:\n",
        "        plt.ylabel('sensitivity',fontsize=fs)\n",
        "    plt.xticks(fontsize=fs)\n",
        "    plt.yticks(fontsize=fs)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "7aNJfbdUmI_U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "* Which parameter are most influential on each performance metric?\n",
        "* Are these results consistent with the visual inspection of the scatter plots?\n",
        "* *Advanced GSA question: What is the impact of changing n and Nboot? Why?*"
      ],
      "metadata": {
        "id": "gJf__nFemI_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate sensitivity indices with Regional Sensitivity Analysis\n",
        "In this section, we repeat the GSA using another method: Regional Sensitivity Analysis (Spear and Hornberger, 1980). We do this to show that multiple approaches are available to perform GSA, but also because the Regional SA approach is tightly connected with the GLUE approach (Beven and Binley 2013) for parameter estimation. For each metric, we need to choose a threshold value to distinguish between 'behavioural' parameter combinations (=those for which the model meets the performance threshold) and 'non-behavioural'. Sensitivity is then measured by the vertical distance between the cumulative distribution of the 'behavioural' parameters and that of the 'non-behavioural'."
      ],
      "metadata": {
        "id": "gmq7O9rsC9Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following cell to choose which performance metric to look at and the associated threshold value:"
      ],
      "metadata": {
        "id": "QTiVgINOKCav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = 'CORRELATION'\n",
        "#metric = 'BIAS'\n",
        "#metric = 'VARIABILITY'\n",
        "#metric = 'KGE'\n",
        "threshold = 0.1 # suggest to vary between 0.02 and 0.1"
      ],
      "metadata": {
        "id": "TW3tgjpdKHaH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and execute the following cell to run the Regional Sensitivity Analysis"
      ],
      "metadata": {
        "id": "OivsIqWmLVdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YY = np.nan * np.ones((N, 4))\n",
        "YY[:, 0] = CORR_ERR(QQ, flow_sel)\n",
        "YY[:, 1] = MEAN_ERR(QQ, flow_sel)\n",
        "YY[:, 2] = STD_ERR(QQ, flow_sel)\n",
        "X_Labels = ['x1', 'x2', 'x3', 'x4', 'x5','x6'] # Name of parameters (used to customize plots)\n",
        "Y_Labels = ['CORRELATION','BIAS','VARIABILITY']\n",
        "\n",
        "if metric == 'CORRELATION':\n",
        "    j = 0\n",
        "elif metric == 'BIAS':\n",
        "    j = 1\n",
        "elif metric == 'VARIABILITY':\n",
        "    j = 2\n",
        "mvd, _, _, idx = RSA_tr.RSA_indices_thres(X, YY[:, j], threshold)\n",
        "plt.figure(figsize=[18,7])\n",
        "for i in range(M):\n",
        "    plt.subplot(2,M,i+1)\n",
        "    plt.plot(X[idx, i], YY[idx,j], '.', markerfacecolor=\"blue\", markeredgecolor=\"grey\")\n",
        "    plt.plot(X[~idx, i], YY[~idx,j], '.', markerfacecolor=\"white\", markeredgecolor=\"grey\")\n",
        "    plt.legend(['behavioural','non-behavioural'],loc=\"upper left\")\n",
        "    plt.xticks([])\n",
        "    if i == 0:\n",
        "        plt.ylabel(Y_Labels[j])\n",
        "    else:\n",
        "        plt.yticks([])\n",
        "    plt.subplot(2,M,M+i+1)\n",
        "    plt.ecdf(X[idx, i],color='blue')\n",
        "    plt.ecdf(X[~idx, i],color='grey')\n",
        "    plt.xlabel(X_Labels[i])\n",
        "    plt.title(\"Sensitivity = %0.2f\" %mvd[i] )\n",
        "    if i == 0:\n",
        "        plt.ylabel('CDF')\n",
        "    else:\n",
        "        plt.yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "FHj9eT4T5oEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions:\n",
        "* Are sensitivity results consistent with the PAWN method?\n",
        "* What other interesting information we can get out of the CDF (Cumulative Distribution Function) plots of the behavioural parameters?"
      ],
      "metadata": {
        "id": "vfT8-vL-GUKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "\n",
        "Beven and Binley (2013). GLUE: 20 years on, Hyd. Proc. 28(24), 5897-5918.\n",
        "\n",
        "Coxon et al. (2020). CAMELS-GB: hydrometeorological time series and landscape attributes for 671 catchments in Great Britain, Earth Syst. Sci. Data, 12, 2459–2483.\n",
        "\n",
        "Pianosi et al. (2015). A Matlab toolbox for Global Sensitivity Analysis’. Env. Mod. & Soft., 70, 80-85.\n",
        "\n",
        "Pianosi and Wagener (2018). Distribution-based sensitivity analysis from a generic input-output sample, Env. Mod. & Soft., 108, 197-207.\n",
        "\n",
        "Pushpalatha, R., Perrin, C., Le Moine, N., Mathevet, T. and Andréassian, V. (2011). A downward structural sensitivity analysis of hydrological models to improve low-flow simulation. Journal of Hydrology, 411(1-2), 66-76, doi:10.1016/j.jhydrol.2011.09.034.\n",
        "\n",
        "Spear and Hornberger (1980). Eutrophication in peel inlet. II. Identification of critical uncertainties via generalized sensitivity analysis, Water Res., 14, 43-49.\n",
        "\n"
      ],
      "metadata": {
        "id": "-M1vcqsBmI_V"
      }
    }
  ]
}
